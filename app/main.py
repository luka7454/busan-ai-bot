import os
import re
import csv
import json
import time
import logging
import asyncio
import urllib.request
from typing import List, Dict, Optional, Tuple

from fastapi import FastAPI, Request, BackgroundTasks
from fastapi.responses import JSONResponse

# -------------------------------
# Logging
# -------------------------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s:  %(message)s")
logger = logging.getLogger("uvicorn.error")

# -------------------------------
# ENV
# -------------------------------
OPENAI_API_KEY      = os.getenv("OPENAI_API_KEY", "")
OPENAI_MODEL        = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")
OPENAI_DEADLINE_MS  = int(os.getenv("OPENAI_DEADLINE_MS", "12000"))   # LLM ì˜ˆì‚°(ì´ˆê³¼ì‹œ ë“œë˜í”„íŠ¸)
MAX_TOKENS          = int(os.getenv("MAX_TOKENS", "480"))

USE_KAKAO_CALLBACK  = os.getenv("USE_KAKAO_CALLBACK", "1") == "1"
CALLBACK_MAX_MS     = int(os.getenv("CALLBACK_MAX_MS", "45000"))      # ì½œë°± í† í° ìœ íš¨ì‹œê°„
CALLBACK_WAIT_TEXT  = os.getenv("CALLBACK_WAIT_TEXT", "ìƒê°ì„ ì •ë¦¬í•˜ê³  ìˆì–´ìš” ğŸ˜Š ìµœëŒ€ 15ì´ˆ ì •ë„ ê±¸ë ¤ìš”.")
FAST_ONLY           = os.getenv("FAST_ONLY", "0") == "1"

GUARD_ENABLED       = os.getenv("GUARD_ENABLED", "1") == "1"

DEFAULT_DATA_DIR    = os.path.join(os.path.dirname(__file__), "data")
DEFAULT_DOCS_DIR    = os.path.join(os.path.dirname(__file__), "docs")
DATA_DIR            = os.getenv("DATA_DIR", DEFAULT_DATA_DIR).rstrip("/")
DOCS_DIR            = os.getenv("DOCS_DIR", DEFAULT_DOCS_DIR).rstrip("/")

# -------------------------------
# Files
# -------------------------------
def read_csv_dicts(filename: str) -> List[Dict]:
    path = os.path.join(DATA_DIR, filename)
    try:
        with open(path, "r", encoding="utf-8-sig") as f:
            return list(csv.DictReader(f))
    except Exception as e:
        logger.warning(f"[CSV] {filename} read fail: {e}")
        return []

def read_md(filename: str) -> str:
    path = os.path.join(DOCS_DIR, filename)
    try:
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except Exception:
        return ""

README_TXT  = read_md("README_jeju_planner_v1.md")
RULE_TXT    = read_md("jeju_rule_engine_spec.md")
ARRIVED_TXT = read_md("jeju_arrived_mode_prompt_hook.md")

# -------------------------------
# Kakao helpers
# -------------------------------
def kakao_text(text: str) -> dict:
    return {"version": "2.0", "template": {"outputs": [{"simpleText": {"text": text}}]}}

def kakao_bubble(text: str) -> dict:
    return {"version": "2.0", "template": {"outputs": [{"simpleText": {"text": text}}]}}

def is_short_greeting(text: str) -> bool:
    t = re.sub(r"\s+", "", text or "")
    return t in {"ì•ˆë…•", "ì•ˆë…•í•˜ì„¸ìš”", "hi", "hello", "ã…ã…‡", "í•˜ì´"}

# ë‚´ë¶€ ê³µê°œìš”êµ¬ë§Œ ì°¨ë‹¨ (ì˜¤íƒ ìµœì†Œí™” + í† ê¸€)
def is_internal_probe(text: str) -> bool:
    if not GUARD_ENABLED:
        return False
    if not text:
        return False
    t = (text or "").lower()

    sens = r"(system\s*prompt|ì‹œìŠ¤í…œ\s*í”„ë¡¬í”„íŠ¸|internal|ë‚´ë¶€|ì§€ì¹¨|ë£°ì—”ì§„|rule\s*engine|ì„¤ì •|spec|ìŠ¤í™|prompt)"
    verb = r"(ë³´ì—¬ì¤˜|ê³µê°œ|ì›ë¬¸|ì›ë³¸|ì¶œë ¥|ë¤í”„|ëˆ„ì„¤|ë…¸ì¶œ|ì„¤ëª…|ì–´ë–»ê²Œ|ì½”ë“œ|ì†ŒìŠ¤|source)"
    pat  = rf"({sens}.*{verb}|{verb}.*{sens})"

    hit = re.search(pat, t)
    if hit:
        logger.warning(f"[Guard HIT] text='{t[:160]}' match='{hit.group(0)}'")
        return True
    return False

# -------------------------------
# Jeju draft (RAT: Retrieval + Augmented Templating)
# -------------------------------
ASK_FLOW = [
    "ëª‡ ë°•ì„ ë¨¸ë¬´ì‹¤ ì˜ˆì •ì¸ê°€ìš”?",
    "ìˆ™ì†Œ ìœ í˜•ì€ ë¬´ì—‡ì¸ê°€ìš”? (í˜¸í…”/ë¦¬ì¡°íŠ¸/ì¼ë°˜í˜¸í…”/íœì…˜/ë¯¼ë°•/ì—¬ê´€)",
    "ì—¬í–‰ ë¶„ìœ„ê¸°ëŠ” ì–´ë””ì— ì§‘ì¤‘í•˜ì‹œë‚˜ìš”? (ë„ì‹œÂ·ë¬¸í™” / ì‚°Â·ìì—° / ë°”ë‹¤Â·í•´ë³€)",
    "ìŒì‹ ì·¨í–¥ì€ ì–´ë–¤ê°€ìš”? (í•´ì‚°ë¬¼ / í•œì‹ / ì¹´í˜Â·ë””ì €íŠ¸ / ê°€ì„±ë¹„ / íŠ¹ë³„í•œ ê²½í—˜ì‹ë‹¹ ë“±)",
    "(ì„ íƒ) ë™í–‰ ì¸ì›Â·êµ¬ì„±ì„ ì•Œë ¤ì£¼ì„¸ìš”. (ì»¤í”Œ / ê°€ì¡±(ì•„ì´ í¬í•¨) / ì¹œêµ¬ / ë‹¨ì²´ ë“±)"
]

def short_greeting_reply() -> str:
    return (
        "ğŸ“Œ ì—¬í–‰ ê¸°ë³¸ íŒ\n"
        "ë¨¼ì € ì—¬í–‰ ì¡°ê±´ ëª‡ ê°€ì§€ë§Œ ì•Œë ¤ì£¼ì‹œë©´ ë”± ë§ê²Œ ì¶”ì²œí•´ë“œë¦´ê²Œìš”.\n\n"
        "ğŸ“ ì¶”ì²œ ì—¬í–‰ì§€ & ì½”ìŠ¤ ì•„ì´ë””ì–´\n"
        f"1) {ASK_FLOW[0]}\n2) {ASK_FLOW[1]}\n3) {ASK_FLOW[2]}\n4) {ASK_FLOW[3]}\n5) {ASK_FLOW[4]}\n\n"
        "ğŸ½ï¸ ë§›ì§‘ ì¶”ì²œ\n"
        "ì¡°ê±´ì„ ì•Œë ¤ì£¼ì‹œë©´ ë™ì„  ë§ì¶° 2~3ê³³ ì¶”ì²œë“œë¦´ê²Œìš”.\n\n"
        "ìµœì‹  ìš´ì˜ì‹œê°„ê³¼ ì˜ˆì•½ì€ ê³µì‹ ì•ˆë‚´ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
    )

def filter_blacklist(pois: List[Dict], bl: List[Dict]) -> List[Dict]:
    blocked = {
        (r.get("poi_id") or r.get("name") or "").strip()
        for r in bl if (r.get("severity") or "").lower() == "high"
    }
    return [p for p in pois if (p.get("poi_id") or p.get("name") or "").strip() not in blocked]

def apply_congestion(pois: List[Dict], rules: List[Dict]) -> Tuple[List[Dict], bool]:
    high = {(r.get("area") or "").strip() for r in rules if (r.get("level") or "").lower() == "high"}
    filtered = [p for p in pois if (p.get("area") or "").strip() not in high]
    return (filtered or pois, len(filtered) < len(pois))

def pick_courses() -> List[Dict]:
    items = read_csv_dicts("jeju_hotel_halftime_courses.csv")
    if not items:
        items = read_csv_dicts("jeju_sample_halfday_courses.csv")
    return items[:3]

def build_draft(utter: str) -> str:
    bl  = read_csv_dicts("jeju_access_blacklist.csv")
    cg  = read_csv_dicts("jeju_congestion_rules.csv")
    raw = pick_courses()
    pois = filter_blacklist(raw, bl)
    pois, congested = apply_congestion(pois, cg)

    tips = [
        "ì´ë™ ì‹œê°„ì€ ì—¬ìœ  ìˆê²Œ 30~40ë¶„ ë‹¨ìœ„ë¡œ ì¡ì•„ì£¼ì„¸ìš”.",
        "ë°”ëŒì´ ê°•í•  ìˆ˜ ìˆì–´ ë°”ëŒë§‰ì´/ìš°ì‚°ì„ ì¤€ë¹„í•˜ì„¸ìš”.",
        "ì£¼ìš” ìŠ¤íŒŸì€ ì£¼ì°¨ ëŒ€ê¸°ê°€ ë°œìƒí•  ìˆ˜ ìˆì–´ìš”.",
    ]
    if congested:
        tips.insert(0, "í˜¼ì¡ êµ¬ê°„ì´ ìˆì–´ ëŒ€ì²´ ì‹œê°„ëŒ€/ì¸ê·¼ ì½”ìŠ¤ë¥¼ ê¶Œì¥í•´ìš”.")

    course_lines = [
        f"- {p.get('name') or p.get('title','ì¶”ì²œ ì½”ìŠ¤')} ({p.get('area','')}) â€” ê³µì‹ ì•ˆë‚´ í™•ì¸ í•„ìš”"
        for p in pois
    ] or ["- ë°˜ë‚˜ì ˆ 2~3ê³³ ìœ„ì£¼ë¡œ ì´ë™ ë™ì„  ìµœì†Œí™”"]

    eat_lines = [
        "- ì¸ê·¼ í•´ì‚°ë¬¼/í•œì‹ ìœ„ì£¼ë¡œ ë™ì„  ë§ì¶° ì¶”ì²œ",
        "- ì¹´í˜Â·ë””ì €íŠ¸ 1ê³³ í¬í•¨í•´ íœ´ì‹ ë™ì„  êµ¬ì„±",
    ]

    return (
        "ğŸ“Œ ì—¬í–‰ ê¸°ë³¸ íŒ\n" + "\n".join(tips[:5]) + "\n\n" +
        "ğŸ“ ì¶”ì²œ ì—¬í–‰ì§€ & ì½”ìŠ¤ ì•„ì´ë””ì–´\n" + "\n".join(course_lines[:5]) + "\n\n" +
        "ğŸ½ï¸ ë§›ì§‘ ì¶”ì²œ\n" + "\n".join(eat_lines[:5]) + "\n\n" +
        "ìµœì‹  ìš´ì˜ì‹œê°„ê³¼ ì˜ˆì•½ì€ ê³µì‹ ì•ˆë‚´ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
    )

# -------------------------------
# OpenAI client
# -------------------------------
client: Optional[object] = None
if OPENAI_API_KEY and not FAST_ONLY:
    try:
        from openai import OpenAI
        client = OpenAI(api_key=OPENAI_API_KEY)
        logger.info("[OpenAI] client init ok")
    except Exception as e:
        logger.warning(f"[OpenAI] client init fail: {e}")
        client = None
else:
    if not OPENAI_API_KEY:
        logger.warning("[OpenAI] missing API key")
    if FAST_ONLY:
        logger.info("[OpenAI] FAST_ONLY=1 (LLM disabled)")

# -------------------------------
# FastAPI app (global)
# -------------------------------
app = FastAPI(title="Jeju ChatPi (Callback)", version="2.3.0")

# -------------------------------
# LLM Polish
# -------------------------------
async def polish_with_llm(utter: str, draft: str, timeout_s: float) -> Optional[str]:
    if FAST_ONLY or not client:
        return None
    try:
        resp = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": (
                    "ë„ˆëŠ” â€œì œì£¼ë„ ì—¬í–‰í”Œë˜ë„ˆ ì±—í”¼(Jeju Travel Planner ChatPi)â€. "
                    "ì œì£¼ê´€ê´‘ê³µì‚¬Â·ì œì£¼ì‹œì²­ ë“± ê³µì‹ ìë£Œì— ê¸°ë°˜í•´ ì •í™•íˆ ì•ˆë‚´í•œë‹¤.\n\n"
                    "ì¶œë ¥ í˜•ì‹(ê° ì„¹ì…˜ 5ì¤„ ì´ë‚´)\n"
                    "ğŸ“Œ ì—¬í–‰ ê¸°ë³¸ íŒ\nğŸ“ ì¶”ì²œ ì—¬í–‰ì§€ & ì½”ìŠ¤ ì•„ì´ë””ì–´\nğŸ½ï¸ ë§›ì§‘ ì¶”ì²œ\n"
                    "í•­ìƒ ë§ˆì§€ë§‰ ì¤„: ìµœì‹  ìš´ì˜ì‹œê°„ê³¼ ì˜ˆì•½ì€ ê³µì‹ ì•ˆë‚´ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
                )},
                {"role": "user", "content": utter},
                {"role": "system", "content": "ì•„ë˜ ì´ˆì•ˆì„ ì œì£¼ ì—¬í–‰ ìŠ¤íƒ€ì¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹¤ë“¬ì–´ ì¶œë ¥:\n" + draft},
            ],
            temperature=0.2,
            max_tokens=MAX_TOKENS,
            timeout=timeout_s,
        )
        text = (resp.choices[0].message.content or "").strip()
        return text if text else None
    except Exception as e:
        logger.warning(f"[OpenAI] error: {e}")
        return None

# -------------------------------
# Callback sender (small retry)
# -------------------------------
def post_callback(callback_url: str, payload: dict) -> Tuple[bool, str]:
    data = json.dumps(payload, ensure_ascii=False).encode("utf-8")
    req = urllib.request.Request(
        callback_url, data=data, headers={"Content-Type": "application/json"}, method="POST"
    )
    for attempt in range(1, 3):
        try:
            with urllib.request.urlopen(req, timeout=10) as r:
                body = r.read().decode("utf-8", "ignore")
            return True, body
        except Exception as e:
            if attempt == 2:
                return False, str(e)
            time.sleep(0.6)
    return False, "unknown"

# -------------------------------
# Routes
# -------------------------------
@app.get("/")
def root():
    return {
        "ok": True,
        "mode": "callback" if USE_KAKAO_CALLBACK else "direct",
        "model": OPENAI_MODEL
    }

@app.get("/health")
def health():
    return {
        "ok": True,
        "use_callback": USE_KAKAO_CALLBACK,
        "fast_only": FAST_ONLY,
        "guard_enabled": GUARD_ENABLED,
        "model": OPENAI_MODEL,
        "deadline_ms": OPENAI_DEADLINE_MS,
        "data_dir": DATA_DIR,
        "docs_dir": DOCS_DIR,
    }

@app.post("/kakao/skill")
async def kakao_skill(request: Request, background_tasks: BackgroundTasks):
    try:
        body = await request.json()
    except Exception:
        body = {}

    user_req    = (body.get("userRequest") or {})
    utter       = (user_req.get("utterance") or "").strip()
    callbackUrl = user_req.get("callbackUrl")

    # ë‚´ë¶€ ì •ë³´ ì°¨ë‹¨ (ì •ë§ 'ë‚´ë¶€ ê³µê°œ ìš”êµ¬'ì¼ ë•Œë§Œ)
    if is_internal_probe(utter):
        logger.warning(f"[Guard] internal probe: {utter}")
        return JSONResponse(kakao_text("ë¹„ë°€ì´ì—ìš” ğŸ¤« ê³µì‹ì ìœ¼ë¡œ ê³µê°œë˜ì§€ ì•Šì€ ì •ë³´ì…ë‹ˆë‹¤."))

    # ì§§ì€ ì¸ì‚¬ ì¦‰ì‹œ ì²˜ë¦¬ (LLM ì—†ì´)
    if is_short_greeting(utter):
        text = short_greeting_reply()
        logger.info(f"[ReplyText] {text[:200].replace(os.linesep,' ')}")
        return JSONResponse(kakao_text(text))

    # ì´ˆê³ ì† ë“œë˜í”„íŠ¸ ìƒì„± (CSV + ê·œì¹™)
    draft = build_draft(utter)

    # ===== ì½œë°± ëª¨ë“œ =====
    if USE_KAKAO_CALLBACK and callbackUrl:
        logger.info("[Callback] useCallback start")

        # ì¦‰ì‹œ ëŒ€ê¸° ì‘ë‹µ (í…œí”Œë¦¿ ì—†ì´ dataë§Œ ë°˜í™˜ â†’ ì½˜ì†”ì—ì„œ 'ìŠ¤í‚¬ë°ì´í„° ì‚¬ìš©'ìœ¼ë¡œ ë§¤í•‘ ê°€ëŠ¥)
        immediate = {"version": "2.0", "useCallback": True, "data": {"text": CALLBACK_WAIT_TEXT}}

        async def job():
            # ì½œë°± ìœ íš¨ì‹œê°„ ì•ˆì—ì„œ LLM ì˜ˆì‚° ì„¤ì • (ìµœëŒ€ 20ì´ˆ)
            llm_budget_s = min(max((CALLBACK_MAX_MS - 2000) / 1000.0, 1.0), 20.0)
            final_text = await polish_with_llm(utter, draft, llm_budget_s)
            if not final_text:
                final_text = draft

            logger.info(f"[CallbackText] {final_text[:200].replace(os.linesep,' ')}")
            payload = kakao_bubble(final_text)
            ok, msg = post_callback(callbackUrl, payload)
            logger.info(f"[Callback] sent={ok} msg={msg[:180]}")

        background_tasks.add_task(job)
        return JSONResponse(immediate)

    # ===== ì¼ë°˜(ë¹„ ì½œë°±) ëª¨ë“œ =====
    if FAST_ONLY or not client:
        logger.info("[Reply] DRAFT (FAST_ONLY or no client)")
        logger.info(f"[ReplyText] {draft[:200].replace(os.linesep,' ')}")
        return JSONResponse(kakao_text(draft))

    async def call_llm():
        return await polish_with_llm(utter, draft, OPENAI_DEADLINE_MS / 1000.0)

    try:
        answer = await asyncio.wait_for(call_llm(), timeout=(OPENAI_DEADLINE_MS / 1000.0 + 0.3))
        if answer:
            logger.info("[Reply] LLM OK")
            logger.info(f"[ReplyText] {answer[:200].replace(os.linesep,' ')}")
            return JSONResponse(kakao_text(answer))
        logger.info("[Reply] DRAFT (no LLM)")
        logger.info(f"[ReplyText] {draft[:200].replace(os.linesep,' ')}")
        return JSONResponse(kakao_text(draft))
    except asyncio.TimeoutError:
        logger.info("[Reply] DRAFT (timeout)")
        logger.info(f"[ReplyText] {draft[:200].replace(os.linesep,' ')}")
        return JSONResponse(kakao_text(draft))
